{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 集成学习\n",
    "基于不同算法的投票决定方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "\n",
    "X,y = datasets.make_moons(n_samples=500,noise=0.3,random_state=42)\n",
    "plt.scatter(X[y==0,0],X[y==0,1])\n",
    "plt.scatter(X[y==1,0],X[y==1,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "trainX,testX,trainY,testY = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 自己实现集成学习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic= 0.872\n",
      "svm= 0.92\n",
      "DecisionTree= 0.864\n",
      "集成= 0.912\n"
     ]
    }
   ],
   "source": [
    "# 逻辑回归\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_clf = LogisticRegression()\n",
    "log_clf.fit(trainX,trainY)\n",
    "print(\"logistic=\",log_clf.score(testX,testY))\n",
    "\n",
    "# SVM\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_clf = SVC()\n",
    "svm_clf.fit(trainX,trainY)\n",
    "print(\"svm=\",svm_clf.score(testX,testY))\n",
    "\n",
    "# 决策树\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "dt_clf.fit(trainX,trainY)\n",
    "print(\"DecisionTree=\",dt_clf.score(testX,testY))\n",
    "\n",
    "# 集成学习\n",
    "yHat1 = log_clf.predict(testX)\n",
    "yHat2 = svm_clf.predict(testX)\n",
    "yHat3 = dt_clf.predict(testX)\n",
    "\n",
    "yHat = np.int32((yHat1+yHat2+yHat3)>=2)\n",
    "yHat\n",
    "ratio = np.sum(yHat==testY)/yHat.shape[0] # accuracy_score\n",
    "print(\"集成=\",ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hard Voting Classifier(少数服从多数)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('log_clf',LogisticRegression()),\n",
    "    ('svm_clf',SVC()),\n",
    "    ('dt_clf',DecisionTreeClassifier())\n",
    "],voting='hard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.912"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.fit(trainX,trainY)\n",
    "voting_clf.score(testX,testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soft Voting Classifier(基于概率)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "voting_clf2 = VotingClassifier(estimators=[\n",
    "    ('log_clf',LogisticRegression()),\n",
    "    ('svm_clf',SVC(probability=True)),# 默认不支持计算概率\n",
    "    ('dt_clf',DecisionTreeClassifier())\n",
    "],voting='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.904"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf2.fit(trainX,trainY)\n",
    "voting_clf2.score(testX,testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 如何创建多个子模型之间的差异性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "每个子模型只看样本数据的一部分，每个子模型不需要太高的准确率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging(放回取样) 和 Pasting(不放回取样)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.928"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "bagging_clf = BaggingClassifier(DecisionTreeClassifier(),\n",
    "                               n_estimators=500,# 子模型数量\n",
    "                               max_samples=100, # 每个子模型的样本数\n",
    "                               bootstrap=True ) # 是否放回，True为放回\n",
    "bagging_clf.fit(trainX,trainY)\n",
    "bagging_clf.score(testX,testY) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.928"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagging_clf = BaggingClassifier(DecisionTreeClassifier(),\n",
    "                               n_estimators=5000,# 子模型数量\n",
    "                               max_samples=100, # 每个子模型的样本数\n",
    "                               bootstrap=True ) # 是否放回，True为放回\n",
    "bagging_clf.fit(trainX,trainY)\n",
    "bagging_clf.score(testX,testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### out-of-bag\n",
    "放回取样导致一部分样本很有可能没有取到<br>\n",
    "不使用测试数据集，而使用这部分没有取到的样本做测试/验证<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "bagging_clf = BaggingClassifier(DecisionTreeClassifier(),\n",
    "                               n_estimators=500,# 子模型数量\n",
    "                               max_samples=100, # 每个子模型的样本数\n",
    "                               bootstrap=True,# 是否放回，True为放回\n",
    "                               oob_score=True)# \n",
    "bagging_clf.fit(X,y)\n",
    "bagging_clf.oob_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### n_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.54 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bagging_clf = BaggingClassifier(DecisionTreeClassifier(),\n",
    "                               n_estimators=5000,# 子模型数量\n",
    "                               max_samples=100, # 每个子模型的样本数\n",
    "                               bootstrap=True,# 是否放回，True为放回\n",
    "                               oob_score=True)# \n",
    "bagging_clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.61 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bagging_clf = BaggingClassifier(DecisionTreeClassifier(),\n",
    "                               n_estimators=5000,# 子模型数量\n",
    "                               max_samples=100, # 每个子模型的样本数\n",
    "                               bootstrap=True,# 是否放回，True为放回\n",
    "                               oob_score=True,\n",
    "                               n_jobs=2)# 几核工作 \n",
    "bagging_clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bootstrap_features(特征随机取样)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.852"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagging_clf = BaggingClassifier(DecisionTreeClassifier(),\n",
    "                               n_estimators=500,# 子模型数量\n",
    "                               max_samples=100, # 每个子模型的样本数\n",
    "                               bootstrap=True,# 是否放回，True为放回\n",
    "                               oob_score=True,\n",
    "                               max_features=1,# 随机选取特征的个数\n",
    "                               bootstrap_features=True)\n",
    "bagging_clf.fit(X,y)\n",
    "bagging_clf.oob_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 随机森林"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=500,\n",
    "                                max_leaf_nodes=16,\n",
    "                                max_depth=3,\n",
    "                                oob_score=True,\n",
    "                               n_jobs=1)\n",
    "rf_clf.fit(X,y)\n",
    "rf_clf.oob_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 集成学习解决回归问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting\n",
    "1. 集成多个模型\n",
    "2. 每个模型都在尝试增强整体的效果（增强未拟合样本点的权重系数）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ada Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://p9tybni1b.bkt.clouddn.com/adaboost.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.896"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "ada_clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=2),n_estimators=30)\n",
    "ada_clf.fit(trainX,trainY)\n",
    "ada_clf.score(testX,testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting\n",
    "根据模型预测错误的值加以修正。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.928"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb_clf = GradientBoostingClassifier(max_depth=2,n_estimators=30)\n",
    "gb_clf.fit(trainX,trainY)\n",
    "gb_clf.score(testX,testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosting解决回归问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://p9tybni1b.bkt.clouddn.com/Stacking.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://p9tybni1b.bkt.clouddn.com/Stacking2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
